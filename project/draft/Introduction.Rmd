Educational or psychological researchers are often interested in assessing people's latent traits that are not directly observable (i.e., self-efficacy). One commonly used assessment method is to develop psychological scales and ask people to rate the scale items. An important assumption of using psychological scales is measurement invariance (MI), meaning the scales have the same measurement properties for people from different groups. By establishing MI, researchers could compare latent means across groups while holding measurement parameters invariant. However, exact invariance (i.e., absolute equivalence in parameter estimates) is often rejected in applied research, so the alignment optimization has been proposed to accurately estimate the latent trait means without requiring the exact invariance across groups [@asparouhov2014]. 

<!-- Specifically, alignment automates the MI analysis by minimizing a loss function that captures the amount of measurement noninvariance across items and groups -->

However, alignment is based on multiple-group confirmatory factor analysis (MG-CFA), in which the variance-covariance matrix and correlations are involved for the calculation of such procedure. It is well-known that the traditional measures of scatter matrix and covariance are sensitive to outliers or data contamination. There are some existing robust estimation methods in structural equation models (SEM), such as the two-stage robust method by @yuan1998a, the direct robust method by @yuan2008, and multivariate-t based SEM by @yuan1998b. However, these robust methods have not been used together with alignment. Thus, the current study propose the robust alignment optimization (RAO) as an alternative to downweigh the impact of data contamination. 

We start the paper with an overview of measurement invariance literature and the alignment optimization. Next, we discuss the existing robust estimation methods in SEM. Then we described the proposed RAO methods in detail. Finally, an illustrative example is included to demonstrate the effectiveness of RAO. We end the paper with a discussion on advantages of the proposed method, as well as limitations and future directions.  

## Measurement Invariance and Alignment

Measurement invariance (MI) holds when individuals with the same level of the latent construct have similar performances on the scale regardless of their group membership [@meredith1993]. If the scale consistently gives higher scores for individuals from one group than the other groups, then the scale violates MI (also called measurement noninvariance). It is an essential assumption for applied researchers to confidently conclude that the observed group differences are due to differences in the latent construct instead of the bias inherent in scale items. One common framework to test MI is the confirmatory factor analysis framework (CFA) [@joreskog1971]. Assume one latent construct is measured by $p$ continuous indicators for $K$ groups. The single factor MG-CFA model can be expressed in the following form,
\begin{equation}
y_{ik} = \tau_k + \lambda_k\eta_{ik} + \epsilon_{ik}. (\#eq:fa)
\end{equation}
Here $y_{ik}$ and $\eta_{ik}$ are the observed continuous response and the latent construct score for the $i$th person in the $k$th group. The three other model parameters are the intercepts, $\nu_k$, factor loadings, $\lambda_k$, and the unique factor variables, $\epsilon_{ik}$. The above model assumes $\epsilon_{ik}$ follows a multivariate normal distribution with a mean vector of 0 and a variance-covariance matrix $\Theta_{ik}$, which is a diagonal matrix that holds the local independence assumption. 

Four levels of invariance have been widely used in existing literature [@meredith1993]. First, configural invariance assumes the same factor structure across groups. Second, metric/weak invariance requires the equality of factor loadings across groups. Third, scalar/strong invariance requires the equality of intercepts across groups in addition to factor loadings. Lastly, strict invariance requires equality of intercepts or thresholds, factor loadings and unique factor variances across groups. 

The equality/invariance of model parameters across groups can be tested by comparing nested models, which means one model with equality constraints of a particular parameter and the other without such constraints. For example, the invariance of intercepts can be tested by comparing the model with freely estimated intercepts and another model that has equality constraints of intercepts across groups. Traditionally, the tenability of the equality constraints is tested by the likelihood ratio test (LRT) or modification indices under NHST [@steiger1985;@shi2019a]. With assumptions of multivariate normality and the null hypothesis of absolute equivalence of model parameters, the likelihood ratio chi-square difference between the nested models follows a central chi-square distribution with degrees of freedom (df) equal to the difference in number of free parameters between models [@shi2019a]. If the test is statistically significant, then the null hypothesis is rejected and researchers could conclude the tested parameter is noninvariant. 

### Alignment

LRT has several limitations. First, it can be time-consuming when the number of group is large [@asparouhov2014]. Second, it tests for exact invariance, which is often violated in applied research. Therefore, @asparouhov2014 proposed the alignment optimization, which simplified the MI testing procedure by using approximate invariance parameter estimates instead of the exact MI results. Alignment has been found to perform well in recovering parameter estimates when the amount of noninvariance is small [@flake2017;@luong2022]. 

The first step of alignment is to fit a configural CFA model, with fixed factor means of 0 and variances of 1 for all groups. Next, alignment frees the factor mean and variance for the reference group and aims to find a set of parameter estimates (loadings and intercepts) that give the same likelihood as the configural model [@muthen2014]. For every set of $\alpha_k$ and $\psi_k$, there are factor loadings and intercepts estimates that fulfill this condition. Specifically, they can be found using equations below [@muthen2014]. 
\begin{align}
\lambda_{jk,1} &= \frac{\lambda_{jk,0}}{\sqrt{\psi_k}}\\
\psi_{jk,1} &= \nu_{jk,0} - \alpha_k \frac{\lambda_{jk,0}}{\sqrt{\psi_k}}
\end{align}
Here $\lambda_{jk,1}$ and $\nu_{jk,1}$ are the factor loading and intercepts estimates that generate the same likelihood as the configural model, whereas $\lambda_{jk,0}$ and $\nu_{jk,0}$ are the parameter estimates from the configural model. 

Next, alignment tries to minimize the total amount of noninvariance across items and groups with respect to $\alpha_k$ and $\psi_k$. The total loss function, $F$, is defined below [@asparouhov2014]  
\begin{align}
F &= \sum_p \sum_{k_1 < k_2}w_{k_1,k_2}f(\lambda_{jk1,1} -\lambda_{jk2,1}) \\ &+ \sum_p \sum_{k_1 < k_2}w_{k_1,k_2}f(\nu_{jk1,1} -\nu_{jk2,1}) 
\end{align}
Here the component loss function $f$, can be set as $f(x) = \sqrt{\sqrt{x^2 + \epsilon}}$ with $\epsilon$ being a small number (i.e., 0.0001). The weight matrix $w_{k_1,k_2}$ reflects the group size and is often set as $w_{k_1,k_2} = \sqrt{N_{k_1} N_{k_2}}$. In other word, the alignment method often generates a solution with a few large noninvariant parameters and many approximate invariant parameters [@asparouhov2014]. 

## Outliers and Leverage Points

Outliers are observations that do not follow the pattern of the majority of the data. Outliers are common in any data set since they do not need to be unusual observations necessarily, they can simply arise because of measurement errors, misplaced decimal points, sampling errors and so on. Methods to detect outliers in univariate data sets have been well studied. However, it is not trivial to detect outliers in a multivariable data cloud. Since the literature for measurement invariance and alignment is built in the framework of confirmatory analysis, it is important to define different types of outliers as the first step in the context of CFA. Consider the factor analysis model described in equation\ \@ref(eq:fa),
<!-- : -->
<!-- $$\textbf{y} = \mu + \Lambda\xi + \epsilon$$  -->
<!-- where $\textbf{y}$ is a vector of $p$ manifest variables, $\mu$ is the vector of population means, $\Lambda$ is a $p \times m$ matrix of factor loadings, $\xi$ isa vector of $m$ factors, and $\epsilon$ contains measurement errors or uniqueness.  -->
it resembes the regression model:
$$\textbf{y} = \beta_{0} + \beta\textbf{X} + \epsilon$$ 
where $\textbf{y}$ is a vector of observed values, $\beta_{0}$ and $\beta$ is the intercept and slope estimates, and $\epsilon$ contains errors, one can regard the factor analysis as a multivariate regression model with latent predictors [@yuan2013]. Thus, the regression model will be used for demonstration of three types of data contamination in a multivariable data set. Leverage points are unusual observation when the dependent variable is ignored, meaning leverage points are outliers among independent variables. Regression outliers refer to observations for
which their residual are outliers based on a regression line that fits the bulk of the points. Bad leverage points are observations that are identified as leverage points and regression outliers. Similarly, in factor analysis, good leverage observations, which are defined as extreme
values in factors but small errors or uniquenesses, enlarge the elements of the sample covariance matrix $\textbf{S}$ and implied covariance matrix $\Sigma(\hat{\Theta})$; outliers and bad leverage points, defined as cases that have extreme values in errors regardless
of the values of the factors, enlarge the elements of S and $\Sigma(\hat{\Theta})$ as well as the residual matrix S - $\Sigma(\hat{\Theta})$; they also result in biased estimates of $\hat{\Lambda}, \hat{\Phi}$ and $\hat{\Psi}$ [@yuan2013]. These concepts are equally applicable to SEM models where prediction errors can be regarded as either factors or errors [@yuan20088].

<!-- The breakdown point of the sample covariance matrix is only 1/n [@wilcox2017modern]. That is, even a single outlier can substantially alter the values of estimates. In multivariate analyses such as CFA, defining, identifying and categorizing data contamination are nontrivial. Given the nature of CFA - parallel to regression, data contamination can be classified into three general categories: leverage points (good and bad), outliers and influential points. Influential points will be the focus for our current project since their inclusion/exclusion will have a great impact on the assessment of the model fit [@yuan2008].  -->

## The Current Study

To our knowledge, there is no discussion on robustness of alignment. Thus, we developed a robust alignment optimization that could produce consistent and efficient estimation with the existence of outliers or influential observations. 

<!-- In this project, we also consider using Projection Method to calculate the distance between each observation and the center of the data cloud. This outlier detection method stands in its own category because it does not require the use of a covariance matrix. More details will be discussed in Method section. -->

